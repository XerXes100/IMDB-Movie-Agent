{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYfBL6RMAPON",
        "outputId": "2bf405c9-3884-476f-b3d3-95b8b37cca71"
      },
      "outputs": [],
      "source": [
        "!pip install langchain\n",
        "!pip install langchain_openai\n",
        "!pip install kagglehub\n",
        "!pip install pandas\n",
        "!pip install langchain_experimental"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXeyXzYsB9cA",
        "outputId": "de1c1afa-9312-44a9-e20a-fd9f8f1c9803"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n"
          ]
        }
      ],
      "source": [
        "from langchain_experimental.agents import create_pandas_dataframe_agent\n",
        "import pandas as pd\n",
        "from langchain_openai import ChatOpenAI\n",
        "import kagglehub\n",
        "import os\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"fernandogarciah24/top-1000-imdb-dataset\")\n",
        "file_path = os.path.join(path, 'imdb_top_1000.csv')\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "import getpass\n",
        "\n",
        "# Enter your OpenAI API Key (It will save it in the environment variable)\n",
        "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
        "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")\n",
        "\n",
        "# Intialize the LLM\n",
        "llm = ChatOpenAI(\n",
        "  temperature=0,\n",
        "  model=\"gpt-4-turbo\",\n",
        "  openai_api_key=os.environ[\"OPENAI_API_KEY\"],\n",
        "  streaming=True,\n",
        ")\n",
        "\n",
        "# Create the agent\n",
        "agent = create_pandas_dataframe_agent(llm, df, allow_dangerous_code=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CjKMO0T3PQJp"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "USAGE OF THE AGENT\n",
        "\n",
        "result = agent.run(<YOUR_QUERY_HERE>)\n",
        "print(result)\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "EcEQLTgiEIsi"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "\n",
        "Questions:\n",
        "\n",
        "1. Please give me a good drama movie released recently.\n",
        "2. What is a good action movie that is longer than 2 hours?\n",
        "3. How many drama movies are there in the top 1000 IMDB movies from the last 5 years?\n",
        "4. Is there any trend in the last 5 years regarding popular movie genres?\n",
        "5. What is the average rating for all movies?\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhKSrhf-PKDi"
      },
      "source": [
        "### Running the agent to answer questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSxaDI4GNWw9",
        "outputId": "649f8b3f-43eb-47ad-b353-23482e6cca52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\"Apollo 13\" is a good drama movie released recently, with a high IMDB rating and positive reviews.\n"
          ]
        }
      ],
      "source": [
        "response = agent.run(\"Please give me a good drama movie released recently.\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TG9injB3NZ6e",
        "outputId": "7788cbc8-30e5-45b5-a341-25128b7f500a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\"The Dark Knight\" is a good action movie that is longer than 2 hours, with a runtime of 152 minutes and an IMDB rating of 9.0.\n"
          ]
        }
      ],
      "source": [
        "response = agent.run(\"What is a good action movie that is longer than 2 hours?\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90E2RG_zNdYX",
        "outputId": "ef8b6e4e-d718-4430-f73f-321911511f2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 76 drama movies in the top 1000 IMDB movies from the last 5 years (2016 to 2020).\n"
          ]
        }
      ],
      "source": [
        "response = agent.run(\"How many drama movies are there in the top 1000 IMDB movies from the last 5 years?\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gmSRC0J3NgyV",
        "outputId": "8ed0ccb4-6a2a-4d39-c78e-307b810f7d72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The provided dataset does not include movies from the last 5 years, so it is not possible to determine any trends in popular movie genres based on this data.\n"
          ]
        }
      ],
      "source": [
        "response = agent.run(\"Is there any trend in the last 5 years regarding popular movie genres?\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRoMDK8YNj9t",
        "outputId": "cc92e928-dcbf-4b9b-81b4-1cc10b5b4009"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The average IMDB rating for all movies in the dataframe is approximately 7.95.\n"
          ]
        }
      ],
      "source": [
        "response = agent.run(\"What is the average rating for all movies?\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# IMDB Movie Agent using Langchain and OpenAI\n",
        "\n",
        "## Overview\n",
        "This project demonstrates the use of Langchain, OpenAI’s GPT-4 model, and a dataset of the top 1000 IMDb movies to build an intelligent agent capable of answering movie-related queries. The agent is powered by Langchain’s `create_pandas_dataframe_agent` function, which uses a DataFrame containing movie data from IMDb to answer user queries intelligently.\n",
        "\n",
        "The code allows for queries like \"Give me a good drama movie released recently\" or other questions about movies using the IMDb dataset.\n",
        "\n",
        "## Prerequisites\n",
        "Before running the project, ensure the following libraries and services are installed and set up:\n",
        "- Python 3.x\n",
        "- Pip (for managing Python packages)\n",
        "\n",
        "### Required Libraries:\n",
        "1. `langchain`: This is the main framework used to build the agent.\n",
        "2. `langchain_openai`: This is used to interface with OpenAI's API for GPT-4.\n",
        "3. `pandas`: For working with the movie dataset.\n",
        "4. `kagglehub`: For downloading datasets from Kaggle.\n",
        "5. `getpass`: For securely entering your OpenAI API key.\n",
        "\n",
        "You can install the necessary libraries with the following commands:\n",
        "\n",
        "```bash\n",
        "pip install langchain\n",
        "pip install langchain_openai\n",
        "pip install kagglehub\n",
        "pip install pandas\n",
        "pip install langchain_experimental\n",
        "```\n",
        "\n",
        "### Setup and Execution\n",
        "\n",
        "1. Obtain the IMDb Dataset using kagglehub:\n",
        "\n",
        "\t```python\n",
        "\timport kagglehub\n",
        "\timport os\n",
        "\n",
        "\t# Download latest version of the IMDb dataset\n",
        "\tpath = kagglehub.dataset_download(\"fernandogarciah24/top-1000-imdb-dataset\")\n",
        "\tfile_path = os.path.join(path, 'imdb_top_1000.csv')\n",
        "\tdf = pd.read_csv(file_path)\n",
        "\t```\n",
        "\n",
        "2. Setup OpenAI API Key:\n",
        "To use OpenAI’s GPT-4 API, you need to provide an API key. You can obtain this API key by signing up for OpenAI services. Once you have the API key, you can set it up in the code using the following snippet:\n",
        "\n",
        "\t```python\n",
        "\timport getpass\n",
        "\n",
        "\t# Enter your OpenAI API Key (It will save it in the environment variable)\n",
        "\tif not os.environ.get(\"OPENAI_API_KEY\"):\n",
        "\t    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")\n",
        "\t```\n",
        "\n",
        "3. Initialize the LLM (Language Model):\n",
        "This section initializes the GPT-4 model using the provided OpenAI API key.\n",
        "\n",
        "\t```python\n",
        "\tfrom langchain_openai import ChatOpenAI\n",
        "\n",
        "\t# Initialize GPT-4 model\n",
        "\tllm = ChatOpenAI(\n",
        "\ttemperature=0,\n",
        "\tmodel=\"gpt-4-turbo\",\n",
        "\topenai_api_key=os.environ[\"OPENAI_API_KEY\"],\n",
        "\tstreaming=True,\n",
        "\t)\n",
        "\t```\n",
        "\n",
        "4. Create the Pandas DataFrame Agent:\n",
        "The agent is created by passing the loaded DataFrame (df) to the create_pandas_dataframe_agent function. This allows the agent to process and respond to queries based on the data stored in the DataFrame. The agent can answer questions about movies in the dataset, such as filtering by genre, rating, or release year.\n",
        "\n",
        "\t```python\n",
        "\tfrom langchain_experimental.agents import create_pandas_dataframe_agent\n",
        "\n",
        "\t# Create the agent\n",
        "\tagent = create_pandas_dataframe_agent(llm, df, allow_dangerous_code=True)\n",
        "\t```\n",
        "\n",
        "5. Run the Agent with a Query:\n",
        "You can now run the agent with a query to get movie recommendations or information. The agent will process the query and provide a response based on the data in the DataFrame.\n",
        "\n",
        "\t```python\n",
        "\texample_query = \"Please give me a good drama movie released recently.\"\n",
        "\tresponse = agent.run(example_query)\n",
        "\tprint(response)\n",
        "\t```\n",
        "\n",
        "6. Viewing Results:\n",
        "Once the query is run, the agent will return a response based on the available movie data. You can change the query to suit different types of movie-related inquiries, such as filtering by genre, release year, rating, and more.\n",
        "\n",
        "### create_pandas_dataframe_agent\n",
        "\n",
        "The create_pandas_dataframe_agent function from Langchain is specifically designed to allow a large language model (LLM) like GPT-4 to directly interact with data stored in a pandas DataFrame. This function provides an easy way to query structured data, enabling the LLM to use the DataFrame as an external knowledge source while processing user queries.\n",
        "\n",
        "#### Why use create_pandas_dataframe_agent?\n",
        "\n",
        "The key reason for using create_pandas_dataframe_agent in this project, as opposed to a Retrieval-Augmented Generation (RAG) approach, is the direct and efficient interaction with the dataset stored in the DataFrame. Here’s why it’s preferred:\n",
        "1. **Data-Specific Queries:**\n",
        "The movie dataset is stored in a structured tabular format (CSV file) that allows the agent to directly search and filter the data. create_pandas_dataframe_agent is optimized for such structured data, providing a more efficient way to answer specific, data-driven queries.\n",
        "2. **Simplicity and Directness:**\n",
        "create_pandas_dataframe_agent simplifies the process of querying a DataFrame. It allows the model to directly access the DataFrame’s rows and columns, which makes it a straightforward choice for this project. There’s no need to complicate the interaction with additional indexing or search systems like those used in RAG.\n",
        "3. **No Need for Document Retrieval:**\n",
        "In RAG, the model retrieves relevant documents from a knowledge base before generating an answer. While this is great for scenarios involving unstructured data, in this case, the dataset is already structured in a DataFrame. The model can directly filter, query, and aggregate data from the DataFrame without needing an external retrieval step.\n",
        "\n",
        "## Current State of the Agent\n",
        "\n",
        "### What the Agent Does Well:\n",
        "- **Efficient Query Handling:** The agent can process various types of queries about movies, including genres, release dates, and more.\n",
        "- **Accurate Responses:** Based on the given IMDb dataset, the agent returns relevant responses.\n",
        "- **Flexible and Adaptable:** The agent is capable of being adapted to other datasets, provided they are in a pandas DataFrame format.\n",
        "\n",
        "### Limitations or Areas for Improvement:\n",
        "- **Inconsistency with current time:** The model cannot provide real-time, up-to-date responses. For example:\n",
        "\t- Example 1: When asked, “How many drama movies are there in the top 1000 IMDb movies from the last 5 years?”, the model will answer based on the data it was trained on (e.g., 2016-2020), but cannot include new data beyond the training set.\n",
        "\t- Example 2: When asked about trends in the last 5 years, the model might respond, “The provided dataset does not include movies from the last 5 years,” as it lacks access to current data.\n",
        "- **Limited Context Understanding**: The agent’s responses are strictly tied to the dataset. If the query involves information outside the dataset (e.g., specific movie details not available in the top 1000 list), the agent may not be able to answer.\n",
        "- **Performance on Complex Queries**: If the dataset grows, the agent may experience latency or performance issues, especially if the queries require complex operations.\n",
        "- **Streaming Mode**: While the model supports streaming, the handling of large responses may need optimization.\n",
        "\n",
        "### Suggestions for Future Enhancements:\n",
        "- **Expand Dataset Coverage**: Integrating more data sources, such as movie reviews, cast information, and director details, could provide a more holistic response to user queries.\n",
        "- **Scalability with RAG:**\n",
        "As the dataset grows larger or if the agent needs to interact with unstructured data sources (like documents, websites, or text-based knowledge bases), implementing RAG can improve scalability. RAG integrates document retrieval into the response generation process, allowing the model to pull relevant information from large, external knowledge sources before generating an answer. This is particularly useful when dealing with more complex queries or when working with unstructured data that doesn’t fit neatly into a DataFrame. Potential benefits of RAG:\n",
        "\t- **Handling Larger Datasets:** RAG can pull relevant context from a large set of documents, enabling the agent to handle complex queries beyond what is available in the current DataFrame.\n",
        "\t- **Expanding the Knowledge Base:** By combining a retrieval mechanism with the model’s generation ability, RAG can make the agent more versatile, allowing it to tap into a broader range of information.\n",
        "- **Improve Query Understanding**: Enhance the agent’s ability to understand more nuanced and complex queries, potentially using natural language processing techniques to process user inputs better.\n",
        "- **Cache Results**: Implementing a caching mechanism could speed up responses for frequently asked queries, reducing computational overhead.\n",
        "- **Add User Feedback**: Allow the agent to learn from user feedback (e.g., thumbs up/down) to improve its responses over time.\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "This agent provides a foundation for building an intelligent movie recommendation system or answering queries related to a movie dataset. While the agent performs well with simple queries, there’s room for growth, especially with regards to expanding the dataset and enhancing the model’s capability to handle more complex queries. By leveraging Langchain, OpenAI, and structured data, this agent showcases the potential of combining AI and data to create intelligent agents for various applications."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
